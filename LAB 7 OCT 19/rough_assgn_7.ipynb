{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Defining plotting settings\n",
    "plt.rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNVanilla(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNNVanilla, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 1000)  # Adjusted the number of input features\n",
    "        self.fc2 = nn.Linear(1000, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-Resnet\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, 1, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNResnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNResnet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.block1 = ResidualBlock(32, 64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool(self.relu(self.conv1(x)))\n",
    "        out = self.pool(self.block1(out))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, num_epochs, learning_rate, device):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    total_step = len(train_loader)\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the model\n",
    "def test_model(model, test_loader, device):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the 10000 test images: {:.2f}%'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lsgrm\\Desktop\\4th year\\7th sem resources\\MLFA Autumn 2023\\Lab\\Lab 2 Aug 10\\LAB 7 OCT 19\\rough_assgn_7.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cnn_vanilla \u001b[39m=\u001b[39m CNNVanilla()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cnn_resnet \u001b[39m=\u001b[39m CNNResnet()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m losses_vanilla \u001b[39m=\u001b[39m train_model(cnn_vanilla, train_loader, num_epochs, learning_rate, device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m losses_resnet \u001b[39m=\u001b[39m train_model(cnn_resnet, train_loader, num_epochs, learning_rate, device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m test_model(cnn_vanilla, test_loader, device)\n",
      "\u001b[1;32mc:\\Users\\lsgrm\\Desktop\\4th year\\7th sem resources\\MLFA Autumn 2023\\Lab\\Lab 2 Aug 10\\LAB 7 OCT 19\\rough_assgn_7.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\lsgrm\\Desktop\\4th year\\7th sem resources\\MLFA Autumn 2023\\Lab\\Lab 2 Aug 10\\assgn1_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lsgrm\\Desktop\\4th year\\7th sem resources\\MLFA Autumn 2023\\Lab\\Lab 2 Aug 10\\assgn1_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\lsgrm\\Desktop\\4th year\\7th sem resources\\MLFA Autumn 2023\\Lab\\Lab 2 Aug 10\\LAB 7 OCT 19\\rough_assgn_7.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lsgrm/Desktop/4th%20year/7th%20sem%20resources/MLFA%20Autumn%202023/Lab/Lab%202%20Aug%2010/LAB%207%20OCT%2019/rough_assgn_7.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main\n",
    "cnn_vanilla = CNNVanilla()\n",
    "cnn_resnet = CNNResnet()\n",
    "\n",
    "losses_vanilla = train_model(cnn_vanilla, train_loader, num_epochs, learning_rate, device)\n",
    "losses_resnet = train_model(cnn_resnet, train_loader, num_epochs, learning_rate, device)\n",
    "\n",
    "test_model(cnn_vanilla, test_loader, device)\n",
    "test_model(cnn_resnet, test_loader, device)\n",
    "\n",
    "# Plot the training losses\n",
    "plt.plot(losses_vanilla, label='CNN-Vanilla')\n",
    "plt.plot(losses_resnet, label='CNN-Resnet')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Latest : \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Defining plotting settings\n",
    "plt.rcParams['figure.figsize'] = 14, 6\n",
    "\n",
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.2470, 0.2435, 0.2616]\n",
    "\n",
    "# Initializing normalizing transform for the dataset\n",
    "normalize_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "# Downloading the CIFAR10 dataset into train and test sets\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./CIFAR10/train\", train=True,\n",
    "    transform=normalize_transform,\n",
    "    download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./CIFAR10/test\", train=False,\n",
    "    transform=normalize_transform,\n",
    "    download=True)\n",
    "\n",
    "# Generating data loaders from the corresponding datasets\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define the Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.downsample = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Define the CNN-Resnet\n",
    "class CNNResnet(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_channels=3):\n",
    "        super(CNNResnet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.res1 = ResidualBlock(32, 32)\n",
    "        self.res2 = ResidualBlock(32, 32)\n",
    "        self.res3 = ResidualBlock(32, 32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.res3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_resnet = CNNResnet().to(device)\n",
    "\n",
    "# Printing model summary\n",
    "print(model_resnet)\n",
    "summary(model_resnet, (3, 32, 32))\n",
    "\n",
    "# Defining the model hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_resnet.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training process begins\n",
    "train_loss_list_resnet = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}:', end=' ')\n",
    "    train_loss = 0\n",
    "\n",
    "    # Iterating over the training dataset in batches\n",
    "    model_resnet.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Extracting images and target labels for the batch being iterated\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Calculating the model output and the cross entropy loss\n",
    "        outputs = model_resnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Updating weights according to calculated loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Printing loss for each epoch\n",
    "    train_loss_list_resnet.append(train_loss / len(train_loader))\n",
    "    print(f\"Training loss = {train_loss_list_resnet[-1]}\")\n",
    "\n",
    "# Plotting loss for all epochs\n",
    "plt.plot(range(1, num_epochs + 1), train_loss_list_resnet)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Latest CNN Vanilla : \n",
    "# Define the CNN-Vanilla\n",
    "class CNNVanilla(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_channels=3):\n",
    "        super(CNNVanilla, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv7 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_vanilla = CNNVanilla().to(device)\n",
    "\n",
    "# Printing model summary\n",
    "print(model_vanilla)\n",
    "summary(model_vanilla, (3, 32, 32))\n",
    "\n",
    "# Defining the model hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_vanilla.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training process begins\n",
    "train_loss_list_vanilla = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}:', end=' ')\n",
    "    train_loss = 0\n",
    "\n",
    "    # Iterating over the training dataset in batches\n",
    "    model_vanilla.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Extracting images and target labels for the batch being iterated\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Calculating the model output and the cross entropy loss\n",
    "        outputs = model_resnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Updating weights according to calculated loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Printing loss for each epoch\n",
    "    train_loss_list_vanilla.append(train_loss / len(train_loader))\n",
    "    print(f\"Training loss = {train_loss_list_vanilla[-1]}\")\n",
    "\n",
    "# Plotting loss for all epochs\n",
    "plt.plot(range(1, num_epochs + 1), train_loss_list_vanilla)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assgn1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
